{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs\n",
    "設定を保存していく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "\nCould not find `optuna-integration` for `lightgbm`.\nPlease run `pip install optuna-integration[lightgbm]`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-23.11.0-0/envs/datasci/lib/python3.13/site-packages/optuna/integration/lightgbm.py:11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptuna_integration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna_integration'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KFold\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mConfig\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-23.11.0-0/envs/datasci/lib/python3.13/site-packages/optuna/integration/lightgbm.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptuna_integration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(_INTEGRATION_IMPORT_ERROR_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlightgbm\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# These modules are from optuna-integration.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightgbm_tuner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LightGBMPruningCallback\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: \nCould not find `optuna-integration` for `lightgbm`.\nPlease run `pip install optuna-integration[lightgbm]`."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error as RMSE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.NB = '001'\n",
    "        self.path_train_data = '../datas/train_raw.csv'\n",
    "        self.path_test_data = '../datas/test_raw.csv'\n",
    "        self.path_submission = f'../submissions/submission{self.NB}.csv'\n",
    "        self.docs_pathname = f'../docs/{self.NB}'\n",
    "        self.img_pathname = f'../images/{self.NB}'\n",
    "        self.data_pathname = f'../datas/{self.NB}'\n",
    "        self.modified_data_pathname = f'../datas/{self.NB}modified_'\n",
    "        self.submit_col = ['id', 'num_sold']\n",
    "        self.pred_col = 'Price'\n",
    "        self.n_estimators = 100\n",
    "        self.n_splits = 5\n",
    "        self.early_stopping_rounds = 150\n",
    "        self.cv_folds = 5\n",
    "        self.ramdom_state = 1234\n",
    "        self.settings = {\n",
    "            'ratio_cols': ['store_sold_ratio', 'product_sold_ratio', 'country_sold_ratio'],\n",
    "            'pred_cols': ['store', 'product', 'country'],\n",
    "            'train_col': ['store', 'product', 'country', 'month','day','year','weekday','week','quarter']\n",
    "        }\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brand_holdout_te</th>\n",
       "      <th>Material_holdout_te</th>\n",
       "      <th>Style_holdout_te</th>\n",
       "      <th>Color_holdout_te</th>\n",
       "      <th>Brand-Material_holdout_te</th>\n",
       "      <th>Brand-Style_holdout_te</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.611723</td>\n",
       "      <td>112.15875</td>\n",
       "      <td>81.819558</td>\n",
       "      <td>80.455028</td>\n",
       "      <td>81.521997</td>\n",
       "      <td>80.501769</td>\n",
       "      <td>80.855173</td>\n",
       "      <td>81.694854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.078537</td>\n",
       "      <td>68.88056</td>\n",
       "      <td>81.769874</td>\n",
       "      <td>82.140962</td>\n",
       "      <td>81.353154</td>\n",
       "      <td>82.417498</td>\n",
       "      <td>82.341131</td>\n",
       "      <td>81.969576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.643760</td>\n",
       "      <td>39.17320</td>\n",
       "      <td>82.068684</td>\n",
       "      <td>80.340901</td>\n",
       "      <td>81.353154</td>\n",
       "      <td>80.886046</td>\n",
       "      <td>80.756973</td>\n",
       "      <td>81.985421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.937220</td>\n",
       "      <td>80.60793</td>\n",
       "      <td>81.202773</td>\n",
       "      <td>80.952390</td>\n",
       "      <td>81.353154</td>\n",
       "      <td>82.417498</td>\n",
       "      <td>80.601946</td>\n",
       "      <td>81.321276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.749338</td>\n",
       "      <td>86.02312</td>\n",
       "      <td>80.592686</td>\n",
       "      <td>82.097783</td>\n",
       "      <td>81.491078</td>\n",
       "      <td>82.447494</td>\n",
       "      <td>81.334032</td>\n",
       "      <td>80.767980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Size  Compartments  Laptop Compartment  Waterproof  \\\n",
       "0   0     1           7.0                   1           0   \n",
       "1   1     2          10.0                   1           1   \n",
       "2   2     2           2.0                   1           0   \n",
       "3   3     2           8.0                   1           0   \n",
       "4   4     1           1.0                   1           1   \n",
       "\n",
       "   Weight Capacity (kg)      Price  Brand_holdout_te  Material_holdout_te  \\\n",
       "0             11.611723  112.15875         81.819558            80.455028   \n",
       "1             27.078537   68.88056         81.769874            82.140962   \n",
       "2             16.643760   39.17320         82.068684            80.340901   \n",
       "3             12.937220   80.60793         81.202773            80.952390   \n",
       "4             17.749338   86.02312         80.592686            82.097783   \n",
       "\n",
       "   Style_holdout_te  Color_holdout_te  Brand-Material_holdout_te  \\\n",
       "0         81.521997         80.501769                  80.855173   \n",
       "1         81.353154         82.417498                  82.341131   \n",
       "2         81.353154         80.886046                  80.756973   \n",
       "3         81.353154         82.417498                  80.601946   \n",
       "4         81.491078         82.447494                  81.334032   \n",
       "\n",
       "   Brand-Style_holdout_te  \n",
       "0               81.694854  \n",
       "1               81.969576  \n",
       "2               81.985421  \n",
       "3               81.321276  \n",
       "4               80.767980  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ferature Engineering\n",
    "def one_hot_encoding(test_df:pd.DataFrame,train_df:pd.DataFrame, cols:list)->pd.DataFrame:\n",
    "    oe = OneHotEncoder(sparse_output=False)\n",
    "    oe.fit(train_df[cols])\n",
    "    encoded_train = oe.transform(train_df[cols])\n",
    "    encoded_test = oe.transform(test_df[cols])\n",
    "    train_df = train_df.drop(cols, axis=1)\n",
    "    test_df = test_df.drop(cols, axis=1)\n",
    "    train_df = pd.concat([train_df, pd.DataFrame(encoded_train, columns=oe.get_feature_names_out(cols))], axis=1)\n",
    "    test_df = pd.concat([test_df, pd.DataFrame(encoded_test, columns=oe.get_feature_names_out(cols))], axis=1)\n",
    "    return test_df, train_df\n",
    "\n",
    "def label_encoding(test_df:pd.DataFrame,train_df:pd.DataFrame, cols:list)->pd.DataFrame:\n",
    "    le = LabelEncoder()\n",
    "    for col in cols:\n",
    "        le.fit(train_df[col])\n",
    "        test_df[col] = le.transform(test_df[col])\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "    return test_df, train_df\n",
    "\n",
    "def holdout_target_encoding(train_df:pd.DataFrame, test_df:pd.DataFrame, target_col:str)->pd.DataFrame:\n",
    "    kf = KFold(n_splits=config.n_splits, shuffle=True, random_state=config.ramdom_state)\n",
    "\n",
    "    box = np.zeros(len(train_df))\n",
    "    for idx_1, idx_2 in kf.split(train_df): # idx_1: train, idx_2: encoding target\n",
    "        target_mean = train_df.iloc[idx_1].groupby(target_col)[config.pred_col].mean()\n",
    "        box[idx_2] = train_df[target_col].iloc[idx_2].map(target_mean)\n",
    "    train_df[f'{target_col}_holdout_te'] = box\n",
    "\n",
    "    target_mean = train_df.groupby(target_col)[config.pred_col].mean()\n",
    "    test_df[f'{target_col}_holdout_te'] = test_df[target_col].map(target_mean)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_datas = pd.read_csv(config.path_train_data)\n",
    "test_datas = pd.read_csv(config.path_test_data)\n",
    "train_datas['Brand-Material'] = train_datas['Brand'] + '-' + train_datas['Material']\n",
    "test_datas['Brand-Material'] = test_datas['Brand'] + '-' + test_datas['Material']\n",
    "train_datas['Brand-Style'] = train_datas['Brand'] + '-' + train_datas['Style']\n",
    "test_datas['Brand-Style'] = test_datas['Brand'] + '-' + test_datas['Style']\n",
    "train_datas, test_datas = holdout_target_encoding(train_datas, test_datas, 'Brand')\n",
    "train_datas, test_datas = holdout_target_encoding(train_datas, test_datas, 'Material')\n",
    "train_datas, test_datas = holdout_target_encoding(train_datas, test_datas, 'Style')\n",
    "train_datas, test_datas = holdout_target_encoding(train_datas, test_datas, 'Color')\n",
    "train_datas, test_datas = holdout_target_encoding(train_datas, test_datas, 'Brand-Material')\n",
    "train_datas, test_datas = holdout_target_encoding(train_datas, test_datas, 'Brand-Style')\n",
    "train_datas = train_datas.drop(['Brand', 'Material', 'Style', 'Brand-Material', 'Brand-Style', 'Color'], axis=1)\n",
    "test_datas = test_datas.drop(['Brand', 'Material', 'Style', 'Brand-Material', 'Brand-Style', 'Color'], axis=1)\n",
    "test_datas, train_datas = label_encoding(test_datas, train_datas, ['Size', 'Waterproof', 'Laptop Compartment'])\n",
    "test_datas.to_csv(f'{config.modified_data_pathname}_test.csv', index=False)\n",
    "train_datas.to_csv(f'{config.modified_data_pathname}_train.csv', index=False)\n",
    "display(train_datas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = pd.read_csv(f'{config.modified_data_pathname}_train.csv')\n",
    "\n",
    "train_datas, test_datas = train_test_split(train_datas, test_size=0.2, random_state=config.ramdom_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "# EDA用の関数を格納する\n",
    "\n",
    "def visualize_statistical_relationships(train_df, cols, stats, **kwargs):\n",
    "    for pair in itertools.combinations(cols, 2):\n",
    "        fig, ax = plt.subplots(1, len(stats), figsize=(10, 5))\n",
    "        for stat in stats:\n",
    "            analysis_df = train_df[[config.pred_col]+list(pair)].pivot_table(index=pair[0], columns=pair[1], values=config.pred_col, aggfunc=stat)\n",
    "            heatmap = sns.heatmap(analysis_df, annot=True, fmt=\".0f\", ax=ax[stats.index(stat)])\n",
    "            ax[stats.index(stat)].set_title(f'train {stat}')\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f'{config.img_pathname}_heatmap_{pair[0]}-{pair[1]}.png')\n",
    "        plt.close()\n",
    "\n",
    "def visualize_statistical_relationships_compare(train_df, cols, stats, **kwargs):\n",
    "    for stat in stats:\n",
    "        fig, ax = plt.subplots(5,2 , figsize=(10, 15))\n",
    "        analysis_dfs = {}\n",
    "        for i, pair in enumerate(itertools.combinations(cols, 2)):\n",
    "            analysis_dfs[pair] = {\"data\":train_df[[config.pred_col]+list(pair)].pivot_table(index=pair[0], columns=pair[1], values=config.pred_col, aggfunc=stat)}\n",
    "            analysis_dfs[pair][\"min\"] = analysis_dfs[pair][\"data\"].min().min()\n",
    "            analysis_dfs[pair][\"max\"] = analysis_dfs[pair][\"data\"].max().max()\n",
    "        vmin = min([analysis_dfs[pair][\"min\"] for pair in analysis_dfs])\n",
    "        vmax = max([analysis_dfs[pair][\"max\"] for pair in analysis_dfs])\n",
    "        for i, key in enumerate(analysis_dfs.keys()):\n",
    "            sns.heatmap(analysis_dfs[key][\"data\"], ax=ax[i//2, i%2], vmin=vmin, vmax=vmax, annot=True, fmt=\".0f\")\n",
    "        fig.suptitle(f'{stat}', fontsize=16)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f'{config.img_pathname}_heatmap_compare_{stat}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = pd.read_csv(config.path_train_data)\n",
    "\n",
    "with open(f'{config.docs_pathname}_eda_train.txt', 'w') as f:\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Datas Info\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    train_datas.info(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Statical Values \\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    train_datas.describe().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Heads \\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    train_datas.head().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('How many nulls \\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    train_datas.isnull().sum().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Unique Values \\n')\n",
    "    train_datas.nunique().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Columns feature \\n')\n",
    "    for col in train_datas.columns:\n",
    "        f.write('\\n')\n",
    "        f.write(f'{col}\\n')\n",
    "        f.write(f'{train_datas[col].unique()}\\n')\n",
    "\n",
    "\n",
    "test_datas = pd.read_csv(config.path_test_data)\n",
    "\n",
    "with open(f'{config.docs_pathname}_eda_test.txt', 'w') as f:\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Datas Info\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    test_datas.info(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Statical Values \\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    test_datas.describe().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Heads \\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    test_datas.head().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('How many nulls \\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    test_datas.isnull().sum().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Unique Values \\n')\n",
    "    test_datas.nunique().to_string(buf=f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('------------------------------------\\n')\n",
    "    f.write('Columns feature \\n')\n",
    "    for col in test_datas.columns:\n",
    "        f.write('\\n')\n",
    "        f.write(f'{col}\\n')\n",
    "        f.write(f'{test_datas[col].unique()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>11.611723</td>\n",
       "      <td>112.15875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Small</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>27.078537</td>\n",
       "      <td>68.88056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Red</td>\n",
       "      <td>16.643760</td>\n",
       "      <td>39.17320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Small</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>12.937220</td>\n",
       "      <td>80.60793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>17.749338</td>\n",
       "      <td>86.02312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         Brand Material    Size  Compartments Laptop Compartment  \\\n",
       "0   0      Jansport  Leather  Medium           7.0                Yes   \n",
       "1   1      Jansport   Canvas   Small          10.0                Yes   \n",
       "2   2  Under Armour  Leather   Small           2.0                Yes   \n",
       "3   3          Nike    Nylon   Small           8.0                Yes   \n",
       "4   4        Adidas   Canvas  Medium           1.0                Yes   \n",
       "\n",
       "  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n",
       "0         No       Tote  Black             11.611723  112.15875  \n",
       "1        Yes  Messenger  Green             27.078537   68.88056  \n",
       "2         No  Messenger    Red             16.643760   39.17320  \n",
       "3         No  Messenger  Green             12.937220   80.60793  \n",
       "4        Yes  Messenger  Green             17.749338   86.02312  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_datas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas1 = train_datas.copy()\n",
    "train_datas = train_datas1.dropna()\n",
    "grouped = train_datas1.groupby(['Brand', 'Material', 'Laptop Compartment', 'Style', 'Color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "cols = ['Brand', 'Material', 'Laptop Compartment', 'Style', 'Color']\n",
    "\n",
    "stats = ['mean', 'std','count']\n",
    "\n",
    "visualize_statistical_relationships(train_datas, cols, stats)\n",
    "\n",
    "visualize_statistical_relationships_compare(train_datas, cols, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
